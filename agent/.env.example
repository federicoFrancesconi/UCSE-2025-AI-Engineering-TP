# Database Configuration
DB_HOST=localhost
DB_PORT=5432
DB_NAME=streaming
DB_USER=your_user
DB_PASSWORD=your_password

# Ollama Configuration
OLLAMA_BASE_URL=http://localhost:11434

# Model Provider: 'ollama' for local models, 'groq' for remote cloud models
MODEL_PROVIDER=groq

# Model Configuration
SQL_MODEL=phi3:mini
CONVERSATION_MODEL=llama3.2:3b
CLASSIFIER_MODEL=phi3:mini

# Groq Model Configuration (used when MODEL_PROVIDER=groq)
GROQ_SQL_MODEL=llama-3.1-8b-instant
GROQ_CONVERSATION_MODEL=llama-3.1-8b-instant
GROQ_CLASSIFIER_MODEL=llama-3.1-8b-instant

# Classifier Configuration
# Set to 'embeddings' to use embedding-based classification, or 'llm' to use LLM-based classification
CLASSIFIER_TYPE=llm

# RAG Configuration
SUMMARIES_DIR=../summaries
EMBEDDING_MODEL=nomic-embed-text
CHROMA_DB_DIR=./chroma_db

# Groq API Key
GROQ_API_KEY=your_groq_api_key
